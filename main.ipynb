{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaFormer\n",
    "\n",
    "论文地址：[MetaFormer is Actually What You Need for Vision](https://arxiv.org/abs/2111.11418)\n",
    "\n",
    "## 简介\n",
    "Transformer已经证明在计算机视觉任务中有非常大的潜力，一种普遍的看法是基于attention的**token mixer**模块使transformer具有竞争力。但是将attention用**spatial MLP**替代后，模型仍然具有非常好的效果。那么是不是**transformer的结构**而不是attention使其有效呢？作者使用**池化层**代替transformer中的**attention**，构建了**PoolFormer**模型，取得了非常好的效果，ImageNet-1k准确率达到82.1%。证明了Transformer结构的有效性，而非attention。\n",
    "\n",
    "本文提出**MetaFormer**：一种从Transformer中抽象出来的**通用架构**，没有指定token mixer，并提出PoolFormer基线在分类、检测和分割任务上进行验证。本次复现在**分类任务**上进行验证实验。各种模型的对比如下图：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e084fdecc43c4b989783b938f85fe76163d7a9aa69304ef2b6a197a4d6adb43c)\n",
    "\n",
    "PoolFormer的网络结构非常简单，只需要把Transformer的Attention模块换成Pooling就可以：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e8eb1384155f42fab8642779150f8fc67d7b2413673e4e2481fe358690a17d69)\n",
    "\n",
    "不同的Pooling模块可以有不同的配置：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4a3ef9fc51a844f8a0485da4808ac1b5cf199f56caf4420b87953a6052ad523e)\n",
    "\n",
    "针对PoolFormer的复现在AiStudio中已经存在，本复现针对**MetaFormer**，并完整复现不同大小网络的MetaFormer\n",
    "\n",
    "## Cifar10数据集\n",
    "\n",
    "链接：http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/15a8790a113d41418d6fc8563aeb4acd10da73b4b8c6488599fa9e7a01cc0833)\n",
    "\n",
    "**CIFAR-10**是一个更接近普适物体的彩色图像数据集。CIFAR-10 是由Hinton 的学生Alex Krizhevsky 和Ilya Sutskever 整理的一个用于识别普适物体的小型数据集。一共包含10 个类别的RGB彩色图片：**飞机**(airplane)、**汽车**(automobile)、**鸟类**(bird)、**猫**(cat)、**鹿**(deer)、**狗**(dog)、**蛙类**(frog)、**马**(horse)、**船**(ship)和**卡车**(truck).\n",
    "\n",
    "每个图片的尺寸为 $32\\times 32$，每个类别有**6000**个图像，数据集中一共有**50000**张训练图片和**10000**张测试图片。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码复现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.引入依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.nn import functional as F\n",
    "from paddle.utils.download import get_weights_path_from_url\n",
    "from paddle import callbacks\n",
    "from paddle.vision.datasets import Cifar10\n",
    "from paddle.io import DataLoader\n",
    "from paddle.optimizer.lr import CosineAnnealingDecay, MultiStepDecay, LinearWarmup\n",
    "from paddle.vision.transforms import (\n",
    "    ToTensor, RandomHorizontalFlip, RandomResizedCrop, SaturationTransform, Compose,\n",
    "    HueTransform, BrightnessTransform, ContrastTransform, RandomCrop, Normalize, RandomRotation, Resize\n",
    ")\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from functools import partial, reduce\n",
    "from typing import Sequence\n",
    "\n",
    "trunc_normal_ = nn.initializer.TruncatedNormal(std=0.02)\n",
    "zeros_ = nn.initializer.Constant(value=0.0)\n",
    "ones_ = nn.initializer.Constant(value=1.0)\n",
    "\n",
    "def drop_path(x, drop_prob=0.0, training=False):\n",
    "\n",
    "    if drop_prob == 0.0 or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "    random_tensor = paddle.to_tensor(keep_prob) + paddle.rand(shape)\n",
    "    random_tensor = paddle.floor(random_tensor)\n",
    "    output = x.divide(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "class DropPath(nn.Layer):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.定义两种Emb方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AddPositionEmb(nn.Layer):\n",
    "    \"\"\"Module to add position embedding to input features\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=384, \n",
    "                spatial_shape=[14, 14]):\n",
    "        super().__init__()\n",
    "        if isinstance(spatial_shape, int):\n",
    "            spatial_shape = [spatial_shape]\n",
    "        assert isinstance(spatial_shape, Sequence), \\\n",
    "            f'\"spatial_shape\" must by a sequence or int, ' \\\n",
    "            f'get {type(spatial_shape)} instead.'\n",
    "        if len(spatial_shape) == 1:\n",
    "            embed_shape = list(spatial_shape) + [dim]\n",
    "        else:\n",
    "            embed_shape = [dim] + list(spatial_shape)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, *embed_shape))\n",
    "        paddle.create_parameter(\n",
    "            shape=[embed_shape],\n",
    "            dtype='float32',\n",
    "            default_initializer=ones_)\n",
    "    def forward(self, x):\n",
    "        return x+self.pos_embed\n",
    "\n",
    "class PatchEmbed(nn.Layer):\n",
    "    \"\"\"\n",
    "    Patch Embedding that is implemented by a layer of conv. \n",
    "    Input: tensor in shape [B, C, H, W]\n",
    "    Output: tensor in shape [B, C, H/stride, W/stride]\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size=16, stride=16, padding=0, \n",
    "                 in_chans=3, embed_dim=768, norm_layer=None):\n",
    "        super().__init__()\n",
    "        patch_size = (patch_size, patch_size)\n",
    "        stride = (stride, stride)\n",
    "        padding = (padding, padding)\n",
    "        self.proj = nn.Conv2D(in_chans, embed_dim, kernel_size=patch_size, \n",
    "                              stride=stride, padding=padding)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.定义Pooling\n",
    "这是本次复现的**核心**，但是它的实现代码**相当简单**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pooling(nn.Layer):\n",
    "    \"\"\"\n",
    "    Implementation of pooling for PoolFormer\n",
    "    --pool_size: pooling size\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AvgPool2D(\n",
    "            kernel_size, stride=1, padding=kernel_size//2, exclusive=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pool(x) - x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.定义Attention机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Layer):\n",
    "    \"\"\"Attention module that can take tensor with [B, N, C] or [B, C, H, W] as input.\n",
    "    Modified from: \n",
    "    https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, head_dim=32, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        assert dim % head_dim == 0, 'dim should be divisible by head_dim'\n",
    "        self.head_dim = head_dim\n",
    "        self.num_heads = dim // head_dim\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        if len(shape) == 4:\n",
    "            B, C, H, W = shape\n",
    "            N = H * W\n",
    "            x = paddle.flatten(x, start_axis=2).transpose(-2, -1) # (B, N, C)\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv.unbind(0)   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        # trick here to make q@k.t more stable\n",
    "        attn = (q * self.scale) @ k.transpose(-2, -1)\n",
    "        # attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        if len(shape) == 4:\n",
    "            x = x.transpose(-2, -1).reshape(B, C, H, W)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.定义LayerNorm和GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LayerNormChannel(nn.Layer):\n",
    "    \"\"\"\n",
    "    LayerNorm only for Channel Dimension.\n",
    "    Input: tensor in shape [B, C, H, W]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels, eps=1e-05):\n",
    "        super().__init__()\n",
    "        self.weight = paddle.create_parameter(\n",
    "            shape=[num_channels],\n",
    "            dtype='float32',\n",
    "            default_initializer=ones_)\n",
    "        self.bias = paddle.create_parameter(\n",
    "            shape=[num_channels],\n",
    "            dtype='float32',\n",
    "            default_initializer=zeros_)\n",
    "        self.epsilon = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "        x = (x - u) / paddle.sqrt(s + self.eps)\n",
    "        x = self.weight.unsqueeze(-1).unsqueeze(-1) * x \\\n",
    "            + self.bias.unsqueeze(-1).unsqueeze(-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GroupNorm(nn.GroupNorm):\n",
    "    \"\"\"\n",
    "    Group Normalization with 1 group.\n",
    "    Input: tensor in shape [B, C, H, W]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels, **kwargs):\n",
    "        super().__init__(1, num_channels, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.定义SpatialFc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpatialFc(nn.Layer):\n",
    "    \"\"\"SpatialFc module that take features with shape of (B,C,*) as input.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, spatial_shape=[14, 14], **kwargs, \n",
    "        ):\n",
    "        super().__init__()\n",
    "        if isinstance(spatial_shape, int):\n",
    "            spatial_shape = [spatial_shape]\n",
    "        assert isinstance(spatial_shape, Sequence), \\\n",
    "            f'\"spatial_shape\" must by a sequence or int, ' \\\n",
    "            f'get {type(spatial_shape)} instead.'\n",
    "        N = reduce(lambda x, y: x * y, spatial_shape)\n",
    "        self.fc = nn.Linear(N, N, bias_attr=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input shape like [B, C, H, W]\n",
    "        shape = x.shape\n",
    "        x = paddle.flatten(x, start_axis=2) # [B, C, H*W]\n",
    "        x = self.fc(x) # [B, C, H*W]\n",
    "        x = paddle.reshape(x, shape) # [B, C, H, W]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.定义MLP\n",
    "**注：与ViT版本有所区别**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mlp(nn.Layer):\n",
    "    \"\"\"\n",
    "    Implementation of MLP with 1*1 convolutions.\n",
    "    Input: tensor with shape [B, C, H, W]\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=None, \n",
    "                 out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Conv2D(in_features, hidden_features, 1)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Conv2D(hidden_features, out_features, 1)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv2D):\n",
    "            trunc_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)     # (B, C, H, W) --> (B, C, H, W)\n",
    "        x = self.act(x)     \n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)     # (B, C, H, W) --> (B, C, H, W)\n",
    "        x = self.drop(x)\n",
    "        return x            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.开始组装，定义MetaFormerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetaFormerBlock(nn.Layer):\n",
    "    \"\"\"\n",
    "    Implementation of one MetaFormer block.\n",
    "    --dim: embedding dim\n",
    "    --token_mixer: token mixer module\n",
    "    --mlp_ratio: mlp expansion ratio\n",
    "    --act_layer: activation\n",
    "    --norm_layer: normalization\n",
    "    --drop: dropout rate\n",
    "    --drop path: Stochastic Depth, \n",
    "        refer to https://arxiv.org/abs/1603.09382\n",
    "    --use_layer_scale, --layer_scale_init_value: LayerScale, \n",
    "        refer to https://arxiv.org/abs/2103.17239\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, \n",
    "                 token_mixer=nn.Identity(), \n",
    "                 mlp_ratio=4., \n",
    "                 act_layer=nn.GELU, norm_layer=LayerNormChannel, \n",
    "                 drop=0., drop_path=0., \n",
    "                 use_layer_scale=True, layer_scale_init_value=1e-5):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.token_mixer = token_mixer()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, \n",
    "                       act_layer=act_layer, drop=drop)\n",
    "        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. \\\n",
    "            else nn.Identity()\n",
    "        self.use_layer_scale = use_layer_scale\n",
    "        if use_layer_scale:\n",
    "            # self.layer_scale_1 = nn.Parameter(\n",
    "            #     layer_scale_init_value * torch.ones((dim)), requires_grad=True)\n",
    "            self.layer_scale_1 = paddle.create_parameter(\n",
    "                                    shape=[dim],\n",
    "                                    dtype='float32',\n",
    "                                    default_initializer=nn.initializer.Constant(value=layer_scale_init_value))\n",
    "            # self.layer_scale_2 = nn.Parameter(\n",
    "            #     layer_scale_init_value * torch.ones((dim)), requires_grad=True)\n",
    "            self.layer_scale_2 = paddle.create_parameter(\n",
    "                                    shape=[dim],\n",
    "                                    dtype='float32',\n",
    "                                    default_initializer=nn.initializer.Constant(value=layer_scale_init_value))\n",
    "\n",
    "        self.drop_path2 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_layer_scale:\n",
    "            x = x + self.drop_path(\n",
    "                self.layer_scale_1.unsqueeze(-1).unsqueeze(-1)\n",
    "                * self.token_mixer(self.norm1(x)))\n",
    "            x = x + self.drop_path(\n",
    "                self.layer_scale_2.unsqueeze(-1).unsqueeze(-1)\n",
    "                * self.mlp(self.norm2(x)))\n",
    "        else:\n",
    "            x = x + self.drop_path(self.token_mixer(self.norm1(x)))\n",
    "            x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.组合basic block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def basic_blocks(dim, index, layers, token_mixer=nn.Identity(), \n",
    "                 mlp_ratio=4., \n",
    "                 act_layer=nn.GELU, norm_layer=LayerNormChannel, \n",
    "                 drop_rate=.0, drop_path_rate=0., \n",
    "                 use_layer_scale=True, layer_scale_init_value=1e-5):\n",
    "    \"\"\"\n",
    "    generate PoolFormer blocks for a stage\n",
    "    return: PoolFormer blocks \n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    for block_idx in range(layers[index]):\n",
    "        block_dpr = drop_path_rate * (\n",
    "            block_idx + sum(layers[:index])) / (sum(layers) - 1)\n",
    "        blocks.append(MetaFormerBlock(\n",
    "            dim, token_mixer=token_mixer, mlp_ratio=mlp_ratio, \n",
    "            act_layer=act_layer, norm_layer=norm_layer, \n",
    "            drop=drop_rate, drop_path=block_dpr, \n",
    "            use_layer_scale=use_layer_scale, \n",
    "            layer_scale_init_value=layer_scale_init_value, \n",
    "            ))\n",
    "    blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-13T12:02:55.522192Z",
     "iopub.status.busy": "2022-06-13T12:02:55.522041Z",
     "iopub.status.idle": "2022-06-13T12:02:55.527308Z",
     "shell.execute_reply": "2022-06-13T12:02:55.526848Z",
     "shell.execute_reply.started": "2022-06-13T12:02:55.522174Z"
    },
    "tags": []
   },
   "source": [
    "### 9.Meta横空出世"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetaFormer(nn.Layer):\n",
    "    \"\"\"\n",
    "    MetaFormer, the main class of our model\n",
    "    --layers: [x,x,x,x], number of blocks for the 4 stages\n",
    "    --embed_dims, --mlp_ratios: the embedding dims and mlp ratios for the 4 stages\n",
    "    --token_mixers: token mixers of different stages\n",
    "    --norm_layer, --act_layer: define the types of normalization and activation\n",
    "    --num_classes: number of classes for the image classification\n",
    "    --in_patch_size, --in_stride, --in_pad: specify the patch embedding\n",
    "        for the input image\n",
    "    --down_patch_size --down_stride --down_pad: \n",
    "        specify the downsample (patch embed.)\n",
    "    --add_pos_embs: position embedding modules of different stages\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, embed_dims=None, \n",
    "                 token_mixers=None, mlp_ratios=None, \n",
    "                 norm_layer=LayerNormChannel, act_layer=nn.GELU, \n",
    "                 num_classes=1000,\n",
    "                 in_patch_size=7, in_stride=4, in_pad=2, \n",
    "                 downsamples=None, down_patch_size=3, down_stride=2, down_pad=1, \n",
    "                 add_pos_embs=None, \n",
    "                 drop_rate=0., drop_path_rate=0.,\n",
    "                 use_layer_scale=True, layer_scale_init_value=1e-5, \n",
    "                 **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            patch_size=in_patch_size, stride=in_stride, padding=in_pad, \n",
    "            in_chans=3, embed_dim=embed_dims[0])\n",
    "        if add_pos_embs is None:\n",
    "            add_pos_embs = [None] * len(layers)\n",
    "        if token_mixers is None:\n",
    "            token_mixers = [nn.Identity()] * len(layers)\n",
    "        # set the main block in network\n",
    "        network = []\n",
    "        for i in range(len(layers)):\n",
    "            if add_pos_embs[i] is not None:\n",
    "                network.append(add_pos_embs[i](embed_dims[i]))\n",
    "            stage = basic_blocks(embed_dims[i], i, layers, \n",
    "                                 token_mixer=token_mixers[i], mlp_ratio=mlp_ratios[i],\n",
    "                                 act_layer=act_layer, norm_layer=norm_layer, \n",
    "                                 drop_rate=drop_rate, \n",
    "                                 drop_path_rate=drop_path_rate,\n",
    "                                 use_layer_scale=use_layer_scale, \n",
    "                                 layer_scale_init_value=layer_scale_init_value)\n",
    "            network.append(stage)\n",
    "            if i >= len(layers) - 1:\n",
    "                break\n",
    "            if downsamples[i] or embed_dims[i] != embed_dims[i+1]:\n",
    "                # downsampling between two stages\n",
    "                network.append(\n",
    "                    PatchEmbed(\n",
    "                        patch_size=down_patch_size, stride=down_stride, \n",
    "                        padding=down_pad, \n",
    "                        in_chans=embed_dims[i], embed_dim=embed_dims[i+1]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        self.network = nn.LayerList(network)\n",
    "        self.norm = norm_layer(embed_dims[-1])\n",
    "        self.head = nn.Linear(\n",
    "            embed_dims[-1], num_classes) if num_classes > 0 \\\n",
    "            else nn.Identity()\n",
    "\n",
    "        self.apply(self.cls_init_weights)\n",
    "\n",
    "    # init for classification\n",
    "    # def cls_init_weights(self, m):\n",
    "    #     if isinstance(m, nn.Linear):\n",
    "    #         trunc_normal_(m.weight)\n",
    "    #         if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "    #             nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def cls_init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                zeros_(m.bias)\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.head\n",
    "\n",
    "    def reset_classifier(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.head = nn.Linear(\n",
    "            self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_embeddings(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        return x\n",
    "\n",
    "    def forward_tokens(self, x):\n",
    "        for idx, block in enumerate(self.network):\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input embedding\n",
    "        x = self.forward_embeddings(x)\n",
    "        # through backbone\n",
    "        x = self.forward_tokens(x)\n",
    "        x = self.norm(x)\n",
    "        # for image classification\n",
    "        cls_out = self.head(x.mean([-2, -1]))\n",
    "        return cls_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.几种不同大小的MetaFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metaformer_id_s12(pretrained=False, **kwargs):\n",
    "    layers = [2, 2, 6, 2]\n",
    "    embed_dims = [64, 128, 320, 512]\n",
    "    token_mixers = [nn.Identity()] * len(layers)\n",
    "    mlp_ratios = [4, 4, 4, 4]\n",
    "    downsamples = [True, True, True, True]\n",
    "    model = MetaFormer(\n",
    "        layers, embed_dims=embed_dims,\n",
    "        token_mixers=token_mixers,\n",
    "        mlp_ratios=mlp_ratios,\n",
    "        norm_layer=GroupNorm,\n",
    "        downsamples=downsamples,\n",
    "        **kwargs)\n",
    "    # model.default_cfg = _cfg(crop_pct=0.9)\n",
    "    return model\n",
    "\n",
    "def metaformer_pppa_s12_224(pretrained=False, **kwargs):\n",
    "    layers = [2, 2, 6, 2]\n",
    "    embed_dims = [64, 128, 320, 512]\n",
    "    add_pos_embs = [None, None, None,\n",
    "        partial(AddPositionEmb, spatial_shape=[7, 7])]\n",
    "    token_mixers = [Pooling, Pooling, Pooling, Attention]\n",
    "    mlp_ratios = [4, 4, 4, 4]\n",
    "    downsamples = [True, True, True, True]\n",
    "    model = MetaFormer(\n",
    "        layers, embed_dims=embed_dims,\n",
    "        token_mixers=token_mixers,\n",
    "        mlp_ratios=mlp_ratios,\n",
    "        downsamples=downsamples,\n",
    "        add_pos_embs=add_pos_embs,\n",
    "        **kwargs)\n",
    "    # model.default_cfg = _cfg()\n",
    "    return model\n",
    "\n",
    "def metaformer_ppaa_s12_224(pretrained=False, **kwargs):\n",
    "    layers = [2, 2, 6, 2]\n",
    "    embed_dims = [64, 128, 320, 512]\n",
    "    add_pos_embs = [None, None, \n",
    "        partial(AddPositionEmb, spatial_shape=[14, 14]), None]\n",
    "    token_mixers = [Pooling, Pooling, Attention, Attention]\n",
    "    mlp_ratios = [4, 4, 4, 4]\n",
    "    downsamples = [True, True, True, True]\n",
    "    model = MetaFormer(\n",
    "        layers, embed_dims=embed_dims,\n",
    "        token_mixers=token_mixers,\n",
    "        mlp_ratios=mlp_ratios,\n",
    "        downsamples=downsamples,\n",
    "        add_pos_embs=add_pos_embs,\n",
    "        **kwargs)\n",
    "    # model.default_cfg = _cfg()\n",
    "    return model\n",
    "\n",
    "def metaformer_pppf_s12_224(pretrained=False, **kwargs):\n",
    "    layers = [2, 2, 6, 2]\n",
    "    embed_dims = [64, 128, 320, 512]\n",
    "    token_mixers = [Pooling, Pooling, Pooling,\n",
    "        partial(SpatialFc, spatial_shape=[7, 7]),\n",
    "        ]\n",
    "    mlp_ratios = [4, 4, 4, 4]\n",
    "    downsamples = [True, True, True, True]\n",
    "    model = MetaFormer(\n",
    "        layers, embed_dims=embed_dims,\n",
    "        token_mixers=token_mixers,\n",
    "        mlp_ratios=mlp_ratios,\n",
    "        norm_layer=GroupNorm,\n",
    "        downsamples=downsamples,\n",
    "        **kwargs)\n",
    "    # model.default_cfg = _cfg(crop_pct=0.9)\n",
    "    return model\n",
    "\n",
    "def metaformer_ppff_s12_224(pretrained=False, **kwargs):\n",
    "    layers = [2, 2, 6, 2]\n",
    "    embed_dims = [64, 128, 320, 512]\n",
    "    token_mixers = [Pooling, Pooling, \n",
    "        partial(SpatialFc, spatial_shape=[14, 14]), \n",
    "        partial(SpatialFc, spatial_shape=[7, 7]),\n",
    "        ]\n",
    "    mlp_ratios = [4, 4, 4, 4]\n",
    "    downsamples = [True, True, True, True]\n",
    "    model = MetaFormer(\n",
    "        layers, embed_dims=embed_dims,\n",
    "        token_mixers=token_mixers,\n",
    "        mlp_ratios=mlp_ratios,\n",
    "        norm_layer=GroupNorm,\n",
    "        downsamples=downsamples,\n",
    "        **kwargs)\n",
    "    # model.default_cfg = _cfg()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-13T12:41:41.946085Z",
     "iopub.status.busy": "2022-06-13T12:41:41.945199Z",
     "iopub.status.idle": "2022-06-13T12:41:42.033504Z",
     "shell.execute_reply": "2022-06-13T12:41:42.032855Z",
     "shell.execute_reply.started": "2022-06-13T12:41:41.946052Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "   Layer (type)        Input Shape          Output Shape         Param #    \n",
      "==============================================================================\n",
      "    Conv2D-29       [[1, 3, 224, 224]]    [1, 64, 56, 56]         9,472     \n",
      "   Identity-43      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "   PatchEmbed-5     [[1, 3, 224, 224]]    [1, 64, 56, 56]           0       \n",
      "   GroupNorm-26     [[1, 64, 56, 56]]     [1, 64, 56, 56]          128      \n",
      "   AvgPool2D-11     [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Pooling-11      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "   Identity-45      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "   GroupNorm-27     [[1, 64, 56, 56]]     [1, 64, 56, 56]          128      \n",
      "    Conv2D-30       [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,640     \n",
      "     GELU-13        [[1, 256, 56, 56]]    [1, 256, 56, 56]          0       \n",
      "    Dropout-13      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Conv2D-31       [[1, 256, 56, 56]]    [1, 64, 56, 56]        16,448     \n",
      "      Mlp-13        [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "MetaFormerBlock-13  [[1, 64, 56, 56]]     [1, 64, 56, 56]          128      \n",
      "   GroupNorm-28     [[1, 64, 56, 56]]     [1, 64, 56, 56]          128      \n",
      "   AvgPool2D-12     [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Pooling-12      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "   Identity-48      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "   GroupNorm-29     [[1, 64, 56, 56]]     [1, 64, 56, 56]          128      \n",
      "    Conv2D-32       [[1, 64, 56, 56]]     [1, 256, 56, 56]       16,640     \n",
      "     GELU-14        [[1, 256, 56, 56]]    [1, 256, 56, 56]          0       \n",
      "    Dropout-14      [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "    Conv2D-33       [[1, 256, 56, 56]]    [1, 64, 56, 56]        16,448     \n",
      "      Mlp-14        [[1, 64, 56, 56]]     [1, 64, 56, 56]           0       \n",
      "MetaFormerBlock-14  [[1, 64, 56, 56]]     [1, 64, 56, 56]          128      \n",
      "    Conv2D-34       [[1, 64, 56, 56]]     [1, 128, 28, 28]       73,856     \n",
      "   Identity-50      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "   PatchEmbed-6     [[1, 64, 56, 56]]     [1, 128, 28, 28]          0       \n",
      "   GroupNorm-30     [[1, 128, 28, 28]]    [1, 128, 28, 28]         256      \n",
      "   AvgPool2D-13     [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Pooling-13      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "   Identity-52      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "   GroupNorm-31     [[1, 128, 28, 28]]    [1, 128, 28, 28]         256      \n",
      "    Conv2D-35       [[1, 128, 28, 28]]    [1, 512, 28, 28]       66,048     \n",
      "     GELU-15        [[1, 512, 28, 28]]    [1, 512, 28, 28]          0       \n",
      "    Dropout-15      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Conv2D-36       [[1, 512, 28, 28]]    [1, 128, 28, 28]       65,664     \n",
      "      Mlp-15        [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "MetaFormerBlock-15  [[1, 128, 28, 28]]    [1, 128, 28, 28]         256      \n",
      "   GroupNorm-32     [[1, 128, 28, 28]]    [1, 128, 28, 28]         256      \n",
      "   AvgPool2D-14     [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Pooling-14      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "   Identity-55      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "   GroupNorm-33     [[1, 128, 28, 28]]    [1, 128, 28, 28]         256      \n",
      "    Conv2D-37       [[1, 128, 28, 28]]    [1, 512, 28, 28]       66,048     \n",
      "     GELU-16        [[1, 512, 28, 28]]    [1, 512, 28, 28]          0       \n",
      "    Dropout-16      [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "    Conv2D-38       [[1, 512, 28, 28]]    [1, 128, 28, 28]       65,664     \n",
      "      Mlp-16        [[1, 128, 28, 28]]    [1, 128, 28, 28]          0       \n",
      "MetaFormerBlock-16  [[1, 128, 28, 28]]    [1, 128, 28, 28]         256      \n",
      "    Conv2D-39       [[1, 128, 28, 28]]    [1, 320, 14, 14]       368,960    \n",
      "   Identity-57      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   PatchEmbed-7     [[1, 128, 28, 28]]    [1, 320, 14, 14]          0       \n",
      "   GroupNorm-34     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   AvgPool2D-15     [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Pooling-15      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   Identity-59      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   GroupNorm-35     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "    Conv2D-40       [[1, 320, 14, 14]]   [1, 1280, 14, 14]       410,880    \n",
      "     GELU-17       [[1, 1280, 14, 14]]   [1, 1280, 14, 14]          0       \n",
      "    Dropout-17      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Conv2D-41      [[1, 1280, 14, 14]]    [1, 320, 14, 14]       409,920    \n",
      "      Mlp-17        [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "MetaFormerBlock-17  [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   GroupNorm-36     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   AvgPool2D-16     [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Pooling-16      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   Identity-62      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   GroupNorm-37     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "    Conv2D-42       [[1, 320, 14, 14]]   [1, 1280, 14, 14]       410,880    \n",
      "     GELU-18       [[1, 1280, 14, 14]]   [1, 1280, 14, 14]          0       \n",
      "    Dropout-18      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Conv2D-43      [[1, 1280, 14, 14]]    [1, 320, 14, 14]       409,920    \n",
      "      Mlp-18        [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "MetaFormerBlock-18  [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   GroupNorm-38     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   AvgPool2D-17     [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Pooling-17      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   Identity-65      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   GroupNorm-39     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "    Conv2D-44       [[1, 320, 14, 14]]   [1, 1280, 14, 14]       410,880    \n",
      "     GELU-19       [[1, 1280, 14, 14]]   [1, 1280, 14, 14]          0       \n",
      "    Dropout-19      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Conv2D-45      [[1, 1280, 14, 14]]    [1, 320, 14, 14]       409,920    \n",
      "      Mlp-19        [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "MetaFormerBlock-19  [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   GroupNorm-40     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   AvgPool2D-18     [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Pooling-18      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   Identity-68      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   GroupNorm-41     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "    Conv2D-46       [[1, 320, 14, 14]]   [1, 1280, 14, 14]       410,880    \n",
      "     GELU-20       [[1, 1280, 14, 14]]   [1, 1280, 14, 14]          0       \n",
      "    Dropout-20      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Conv2D-47      [[1, 1280, 14, 14]]    [1, 320, 14, 14]       409,920    \n",
      "      Mlp-20        [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "MetaFormerBlock-20  [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   GroupNorm-42     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   AvgPool2D-19     [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Pooling-19      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   Identity-71      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   GroupNorm-43     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "    Conv2D-48       [[1, 320, 14, 14]]   [1, 1280, 14, 14]       410,880    \n",
      "     GELU-21       [[1, 1280, 14, 14]]   [1, 1280, 14, 14]          0       \n",
      "    Dropout-21      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Conv2D-49      [[1, 1280, 14, 14]]    [1, 320, 14, 14]       409,920    \n",
      "      Mlp-21        [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "MetaFormerBlock-21  [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   GroupNorm-44     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "   AvgPool2D-20     [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Pooling-20      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   Identity-74      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "   GroupNorm-45     [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "    Conv2D-50       [[1, 320, 14, 14]]   [1, 1280, 14, 14]       410,880    \n",
      "     GELU-22       [[1, 1280, 14, 14]]   [1, 1280, 14, 14]          0       \n",
      "    Dropout-22      [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "    Conv2D-51      [[1, 1280, 14, 14]]    [1, 320, 14, 14]       409,920    \n",
      "      Mlp-22        [[1, 320, 14, 14]]    [1, 320, 14, 14]          0       \n",
      "MetaFormerBlock-22  [[1, 320, 14, 14]]    [1, 320, 14, 14]         640      \n",
      "    Conv2D-52       [[1, 320, 14, 14]]     [1, 512, 7, 7]       1,475,072   \n",
      "   Identity-76       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "   PatchEmbed-8     [[1, 320, 14, 14]]     [1, 512, 7, 7]           0       \n",
      "   GroupNorm-46      [[1, 512, 7, 7]]      [1, 512, 7, 7]         1,024     \n",
      "     Linear-4         [[1, 512, 49]]        [1, 512, 49]          2,401     \n",
      "   SpatialFc-3       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "   Identity-78       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "   GroupNorm-47      [[1, 512, 7, 7]]      [1, 512, 7, 7]         1,024     \n",
      "    Conv2D-53        [[1, 512, 7, 7]]     [1, 2048, 7, 7]       1,050,624   \n",
      "     GELU-23        [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0       \n",
      "    Dropout-23       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "    Conv2D-54       [[1, 2048, 7, 7]]      [1, 512, 7, 7]       1,049,088   \n",
      "      Mlp-23         [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "MetaFormerBlock-23   [[1, 512, 7, 7]]      [1, 512, 7, 7]         1,024     \n",
      "   GroupNorm-48      [[1, 512, 7, 7]]      [1, 512, 7, 7]         1,024     \n",
      "     Linear-5         [[1, 512, 49]]        [1, 512, 49]          2,401     \n",
      "   SpatialFc-4       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "   Identity-81       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "   GroupNorm-49      [[1, 512, 7, 7]]      [1, 512, 7, 7]         1,024     \n",
      "    Conv2D-55        [[1, 512, 7, 7]]     [1, 2048, 7, 7]       1,050,624   \n",
      "     GELU-24        [[1, 2048, 7, 7]]     [1, 2048, 7, 7]           0       \n",
      "    Dropout-24       [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "    Conv2D-56       [[1, 2048, 7, 7]]      [1, 512, 7, 7]       1,049,088   \n",
      "      Mlp-24         [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "MetaFormerBlock-24   [[1, 512, 7, 7]]      [1, 512, 7, 7]         1,024     \n",
      "   GroupNorm-50      [[1, 512, 7, 7]]      [1, 512, 7, 7]         1,024     \n",
      "     Linear-6           [[1, 512]]           [1, 1000]           513,000    \n",
      "==============================================================================\n",
      "Total params: 11,919,978\n",
      "Trainable params: 11,919,978\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 142.51\n",
      "Params size (MB): 45.47\n",
      "Estimated Total Size (MB): 188.55\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 11919978, 'trainable_params': 11919978}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = metaformer_pppf_s12_224()\n",
    "paddle.summary(net, (1,3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.定义数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToArray(object):\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        img = np.transpose(img, [2, 0, 1])\n",
    "        img = img / 255.\n",
    "        return img.astype('float32')\n",
    "\n",
    "class RandomApply(object):\n",
    "    def __init__(self, transform, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.p < random.random():\n",
    "            return img\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "                                                                                                                    \n",
    "class LRSchedulerM(callbacks.LRScheduler):                                                                                                           \n",
    "    def __init__(self, by_step=False, by_epoch=True, warm_up=True):                                                                                                \n",
    "        super().__init__(by_step, by_epoch)                                                                                                                          \n",
    "        assert by_step ^ warm_up\n",
    "        self.warm_up = warm_up\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.by_epoch and not self.warm_up:\n",
    "            if self.model._optimizer and hasattr(\n",
    "                self.model._optimizer, '_learning_rate') and isinstance(\n",
    "                    self.model._optimizer._learning_rate, paddle.optimizer.lr.LRScheduler):                                                                                         \n",
    "                self.model._optimizer._learning_rate.step()                                                                                          \n",
    "                                                                                                                                                     \n",
    "    def on_train_batch_end(self, step, logs=None):                                                                                                   \n",
    "        if self.by_step or self.warm_up:                                                                                                                             \n",
    "            if self.model._optimizer and hasattr(\n",
    "                self.model._optimizer, '_learning_rate') and isinstance(\n",
    "                    self.model._optimizer._learning_rate, paddle.optimizer.lr.LRScheduler):                                                                                         \n",
    "                self.model._optimizer._learning_rate.step()\n",
    "            if self.model._optimizer._learning_rate.last_epoch >= self.model._optimizer._learning_rate.warmup_steps:\n",
    "                self.warm_up = False\n",
    "\n",
    "def _on_train_batch_end(self, step, logs=None):\n",
    "    logs = logs or {}\n",
    "    logs['lr'] = self.model._optimizer.get_lr()\n",
    "    self.train_step += 1\n",
    "    if self._is_write():\n",
    "        self._updates(logs, 'train')\n",
    "\n",
    "def _on_train_begin(self, logs=None):\n",
    "    self.epochs = self.params['epochs']\n",
    "    assert self.epochs\n",
    "    self.train_metrics = self.params['metrics'] + ['lr']\n",
    "    assert self.train_metrics\n",
    "    self._is_fit = True\n",
    "    self.train_step = 0\n",
    "\n",
    "callbacks.VisualDL.on_train_batch_end = _on_train_batch_end\n",
    "callbacks.VisualDL.on_train_begin = _on_train_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = paddle.Model(metaformer_pppf_s12_224(num_classes=10))\n",
    "# 加载checkpoint\n",
    "# model.load('output/metaformer_pppf_s12_224/299.pdparams')\n",
    "MAX_EPOCH = 300\n",
    "LR = 0.001\n",
    "WEIGHT_DECAY = 5e-4\n",
    "MOMENTUM = 0.9\n",
    "BATCH_SIZE = 12\n",
    "CIFAR_MEAN = [0.5071, 0.4865, 0.4409]\n",
    "CIFAR_STD = [0.1942, 0.1918, 0.1958]\n",
    "DATA_FILE = None\n",
    "\n",
    "model.prepare(\n",
    "    paddle.optimizer.Momentum(\n",
    "        learning_rate=LinearWarmup(CosineAnnealingDecay(LR, MAX_EPOCH), 2000, 0., LR),\n",
    "        momentum=MOMENTUM,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=WEIGHT_DECAY),\n",
    "    paddle.nn.CrossEntropyLoss(),\n",
    "    paddle.metric.Accuracy(topk=(1,5)))\n",
    "\n",
    "# 定义数据集增强方式\n",
    "transforms = Compose([\n",
    "    Resize(size=224),\n",
    "    ToArray(),\n",
    "    Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "])\n",
    "val_transforms = Compose([Resize(size=224), ToArray(), Normalize(CIFAR_MEAN, CIFAR_STD)])\n",
    "\n",
    "# 加载训练和测试数据集\n",
    "train_set = Cifar10(DATA_FILE, mode='train', transform=transforms)\n",
    "test_set = Cifar10(DATA_FILE, mode='test', transform=val_transforms)\n",
    "\n",
    "# 定义保存方式和训练可视化\n",
    "checkpoint_callback = paddle.callbacks.ModelCheckpoint(save_freq=1, save_dir='output/metaformer_pppf_s12_224')\n",
    "callbacks = [LRSchedulerM(),checkpoint_callback, callbacks.VisualDL('vis_logs/metaformer_pppf_s12_224.log')]\n",
    "\n",
    "# 训练模型\n",
    "model.fit(\n",
    "    train_set,\n",
    "    test_set,\n",
    "    epochs=MAX_EPOCH, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    verbose=1, \n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "最近复现了几篇Transformer领域的论文，非常感谢百度李老师的指导，复现过程比自己以为的要更加轻松，通过复现这种相对比较简单的网络结构，让我能够深入理解网络的运行过程，对Transformer的理解更加深入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
